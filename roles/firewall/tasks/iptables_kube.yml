- name: Kube Firewall | Allow port 6443 inbound to Kube Manager from all kube nodes
  iptables:
    chain: INPUT
    protocol: tcp
    destination_port: 6443
    source: "{{ item }}"
    jump: ACCEPT
  loop: "{{ groups['kubemgr'] + groups['kube'] }}"

# Allow kubelet API access (10250/tcp) 
- name: Kube Firewall | Allow port 10250 inbound from all kube nodes
  iptables:
    chain: INPUT
    protocol: tcp
    destination_port: 10250
    source: "{{ item }}"
    jump: ACCEPT
  loop: "{{ groups['kubemgr'] + groups['kube'] }}"

# Allow Flannel VXLAN (8472/udp)
- name: Kube Firewall | Allow port 8472 UDP inbound from all kube nodes for Flannel
  iptables:
    chain: INPUT
    protocol: udp
    destination_port: 8472
    source: "{{ item }}"
    jump: ACCEPT
  loop: "{{ groups['kubemgr'] + groups['kube'] }}"

# Allow pod network CIDR traffic to reach master
- name: Kube Firewall | Allow pod network CIDR to master nodes
  iptables:
    chain: INPUT
    source: "{{ pod_network_cidr }}"
    jump: ACCEPT

#shell because multi ports
- name: Kube Firewall | Allow NodePort range 30000-32767 from all kube nodes
  shell: |
    iptables -C INPUT -p tcp --dport 30000:32767 -s {{ item }} -j ACCEPT 2>/dev/null || \
    iptables -A INPUT -p tcp --dport 30000:32767 -s {{ item }} -j ACCEPT
  loop: "{{ groups['kubemgr'] + groups['kube'] }}"

- name: Kube Firewall | Save iptables rules | Debian
  shell: iptables-save > /etc/iptables/rules.v4
  when: ansible_os_family == "Debian"

- name: Kube Firewall | Save iptables rules | RHEL
  shell: service iptables save
  when: ansible_os_family == "RedHat"

#https://docs.oracle.com/en/operating-systems/olcne/1.1/start/ports.html
#
#Our boxes <===> 6443/tcp: Kubernetes Api Server on Control Plane
#All Kube Nodes <===> 10250/tcp: Kubernetes kubelet API server on master and worker nodes
#All Kube Nodes <===> 8472/udp: Flannel overlay network if using VxLAN backend on master and worker nodes (REPLACE IF USING DIFFERENT CNI)
#Allow traffic from the defined pod network CIDR to reach your Kubernetes master node. This ensures pods can communicate with the API server
#
#SPECIAL CASES:
#Master Nodes <===> 2379/tcp: Kubernetes etcd server client API on master nodes in multi-master deployments
#Master Nodes <===> 2380/tcp: Kubernetes etcd server client API on master nodes in multi-master deployments
#Master Nodes <===> 10251/tcp: Kubernetes kube-scheduler on master nodes in multi-master deployments
#Master Nodes <===> 10252/tcp: Kubernetes kube-controller-manager on master nodes in multi-master deployments